apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  labels:
    app.kubernetes.io/name: kube-prometheus
    app.kubernetes.io/part-of: kube-prometheus
    prometheus: k8s
    role: alert-rules
    release: kube-prometheus-stack
  name: prometheus-k8s-rules
  namespace: monitoring
spec:
  groups:
  - name: k8s.rules
    rules:
      # 计算每个命名空间、工作区和集群的容器CPU使用率总和
    - expr: |
        sum (irate(container_cpu_usage_seconds_total{job="kubelet", image!="", container!=""}[5m]) * on(namespace, cluster) group_left(workspace) kube_namespace_labels{job="kube-state-metrics"}) by (namespace, workspace, cluster)
        or on(namespace, workspace, cluster) max by(namespace, workspace, cluster) (kube_namespace_labels * 0)
      record: namespace:container_cpu_usage_seconds_total:sum_rate
      # 计算每个命名空间、工作区和集群的容器内存使用总量
    - expr: |
        sum(container_memory_usage_bytes{job="kubelet", image!="", container!=""} * on(namespace, cluster) group_left(workspace) kube_namespace_labels{job="kube-state-metrics"}) by (namespace, workspace, cluster)
        or on(namespace, workspace, cluster) max by(namespace, workspace, cluster) (kube_namespace_labels * 0)
      record: namespace:container_memory_usage_bytes:sum
      # 计算每个命名空间、工作区和集群的容器工作集内存使用总量（不含缓存）
    - expr: |
        sum(container_memory_working_set_bytes{job="kubelet", image!="", container!=""} * on(namespace, cluster) group_left(workspace) kube_namespace_labels{job="kube-state-metrics"}) by (namespace, workspace, cluster)
        or on(namespace, workspace, cluster) max by(namespace, workspace, cluster) (kube_namespace_labels * 0)
      record: namespace:container_memory_usage_bytes_wo_cache:sum
      # 计算每个命名空间、标签名和集群的Pod容器内存请求总量
    - expr: |
        sum by (namespace, label_name, cluster) (
            sum(kube_pod_container_resource_requests{resource="memory", job="kube-state-metrics"} * on (endpoint, instance, job, namespace, pod, service, cluster) group_left(phase) (kube_pod_status_phase{phase=~"Pending|Running"} == 1)) by (namespace, pod, cluster)
          * on (namespace, pod, cluster)
            group_left(label_name) kube_pod_labels{job="kube-state-metrics"}
        )
      record: namespace_memory:kube_pod_container_resource_requests:sum
      # 计算每个命名空间、标签名和集群的Pod容器CPU请求总量
    - expr: |
        sum by (namespace, label_name, cluster) (
            sum(kube_pod_container_resource_requests{resource="cpu", job="kube-state-metrics"} * on (endpoint, instance, job, namespace, pod, service, cluster) group_left(phase) (kube_pod_status_phase{phase=~"Pending|Running"} == 1)) by (namespace, pod, cluster)
          * on (namespace, pod, cluster)
            group_left(label_name) kube_pod_labels{job="kube-state-metrics"}
        )
      record: namespace_cpu:kube_pod_container_resource_requests:sum
  - name: node.rules
    rules:
      # 计算每个CPU核心在user、nice、system、iowait、irq、softirq模式下的使用时间总和
    - expr: |
        sum (node_cpu_seconds_total{job="node-exporter", mode=~"user|nice|system|iowait|irq|softirq"}) by (cpu, instance, job, namespace, pod, cluster)
      record: node_cpu_used_seconds_total
      # 获取每个节点上不同QOS（质量服务等级）的Pod信息，包括Pod的拥有者信息
    - expr: |
        max by (namespace,pod,node,owner_name,owner_kind,qos, cluster)(kube_pod_info{job="kube-state-metrics"}
          * on (namespace, pod, cluster) group_left(owner_kind, owner_name) kube_pod_owner{job="kube-state-metrics"}
          * on (namespace,pod, cluster) group_left(qos) max by (namespace,pod,qos, cluster)
            ((label_replace(container_memory_working_set_bytes{job="kubelet", container="",pod!="",id=~".*(burstable|besteffort).*"},"qos","$1","id",".*(burstable|besteffort).*")
            or label_replace(container_memory_working_set_bytes{job="kubelet", container="",pod!="",id!~".*(burstable|besteffort).*"},"qos","guaranteed","id",".*")) > bool 0))
      record: 'qos_owner_node:kube_pod_info:'
      # 获取每个节点上角色为master的Pod信息，包括节点和主机IP信息
    - expr: |
        max(kube_pod_info{job="kube-state-metrics"} * on(node, cluster) group_left(role) kube_node_role{job="kube-state-metrics", role="master"} or on(pod, namespace, cluster) kube_pod_info{job="kube-state-metrics"}) by (node, namespace, host_ip, role, pod, cluster)
      record: 'node_namespace_pod:kube_pod_info:'
      # 计算每个节点的CPU核心数量
    - expr: |
        count by (node, host_ip, role, cluster) (sum by (node, cpu, host_ip, role, cluster) (
          node_cpu_seconds_total{job="node-exporter"}
        * on (namespace, pod, cluster) group_left(node, host_ip, role)
          node_namespace_pod:kube_pod_info:
        ))
      record: node:node_num_cpu:sum
      # 计算每个集群内CPU的1分钟平均利用率
    - expr: |
        avg by(cluster) (irate(node_cpu_used_seconds_total{job="node-exporter"}[5m]))
      record: :node_cpu_utilisation:avg1m
      # 计算每个节点的1分钟平均CPU利用率
    - expr: |
        avg by (node, host_ip, role, cluster) (
          irate(node_cpu_used_seconds_total{job="node-exporter"}[5m])
        * on (namespace, pod, cluster) group_left(node, host_ip, role)
          node_namespace_pod:kube_pod_info:)
      record: node:node_cpu_utilisation:avg1m
      # 计算集群的内存利用率，1表示100%使用率
    - expr: |
        1 -
        sum by(cluster) (node_memory_MemFree_bytes{job="node-exporter"} + node_memory_Cached_bytes{job="node-exporter"} + node_memory_Buffers_bytes{job="node-exporter"} + node_memory_SReclaimable_bytes{job="node-exporter"})
        /
        sum by(cluster) (node_memory_MemTotal_bytes{job="node-exporter"})
      record: ':node_memory_utilisation:'
      # 计算每个节点的可用内存量，包含空闲内存、缓存、缓冲区、可回收的内存
    - expr: |
        sum by (node, host_ip, role, cluster) (
          (node_memory_MemFree_bytes{job="node-exporter"} + node_memory_Cached_bytes{job="node-exporter"} + node_memory_Buffers_bytes{job="node-exporter"} + node_memory_SReclaimable_bytes{job="node-exporter"})
          * on (namespace, pod, cluster) group_left(node, host_ip, role)
            node_namespace_pod:kube_pod_info:
        )
      record: node:node_memory_bytes_available:sum
      # 计算每个节点的内存总量
    - expr: |
        sum by (node, host_ip, role, cluster) (
          node_memory_MemTotal_bytes{job="node-exporter"}
          * on (namespace, pod, cluster) group_left(node, host_ip, role)
            node_namespace_pod:kube_pod_info:
        )
      record: node:node_memory_bytes_total:sum
      # 计算内存利用率（1表示100%使用率）
    - expr: |
        1 - (node:node_memory_bytes_available:sum / node:node_memory_bytes_total:sum)
      record: 'node:node_memory_utilisation:'
      # 计算每个节点的数据卷读操作的IOPS
    - expr: |
        sum by (node, host_ip, role, cluster) (
          irate(node_disk_reads_completed_total{job="node-exporter"}[5m])
        * on (namespace, pod, cluster) group_left(node, host_ip, role)
          node_namespace_pod:kube_pod_info:
        )
      record: node:data_volume_iops_reads:sum
      # 计算每个节点的数据卷写操作的IOPS
    - expr: |
        sum by (node, host_ip, role, cluster) (
          irate(node_disk_writes_completed_total{job="node-exporter"}[5m])
        * on (namespace, pod, cluster) group_left(node, host_ip, role)
          node_namespace_pod:kube_pod_info:
        )
      record: node:data_volume_iops_writes:sum
      # 计算每个节点的数据卷读操作的吞吐量（字节数）
    - expr: |
        sum by (node, host_ip, role, cluster) (
          irate(node_disk_read_bytes_total{job="node-exporter"}[5m])
        * on (namespace, pod, cluster) group_left(node, host_ip, role)
          node_namespace_pod:kube_pod_info:
        )
      record: node:data_volume_throughput_bytes_read:sum
      # 计算每个节点的数据卷写操作的吞吐量（字节数）
    - expr: |
        sum by (node, host_ip, role, cluster) (
          irate(node_disk_written_bytes_total{job="node-exporter"}[5m])
        * on (namespace, pod, cluster) group_left(node, host_ip, role)
          node_namespace_pod:kube_pod_info:
        )
      record: node:data_volume_throughput_bytes_written:sum
      # 计算整个集群的网络利用率（接收和发送的字节数）
    - expr: |
        sum by(cluster) (irate(node_network_receive_bytes_total{job="node-exporter",device!~"veth.+"}[5m])) +
        sum by(cluster) (irate(node_network_transmit_bytes_total{job="node-exporter",device!~"veth.+"}[5m]))
      record: :node_net_utilisation:sum_irate
      # 计算每个节点的网络利用率（接收和发送的字节数）
    - expr: |
        sum by (node, host_ip, role, cluster) (
          (irate(node_network_receive_bytes_total{job="node-exporter",device!~"veth.+"}[5m]) +
          irate(node_network_transmit_bytes_total{job="node-exporter",device!~"veth.+"}[5m]))
        * on (namespace, pod, cluster) group_left(node, host_ip, role)
          node_namespace_pod:kube_pod_info:
        )
      record: node:node_net_utilisation:sum_irate
      # 计算每个节点发送的网络字节数
    - expr: |
        sum by (node, host_ip, role, cluster) (
          irate(node_network_transmit_bytes_total{job="node-exporter",device!~"veth.+"}[5m])
        * on (namespace, pod, cluster) group_left(node, host_ip, role)
          node_namespace_pod:kube_pod_info:
        )
      record: node:node_net_bytes_transmitted:sum_irate
      # 计算每个节点接收的网络字节数
    - expr: |
        sum by (node, host_ip, role, cluster) (
          irate(node_network_receive_bytes_total{job="node-exporter",device!~"veth.+"}[5m])
        * on (namespace, pod, cluster) group_left(node, host_ip, role)
          node_namespace_pod:kube_pod_info:
        )
      record: node:node_net_bytes_received:sum_irate
      # 计算每个节点的inode总数
    - expr: |
        sum by(node, host_ip, role, cluster) (sum(max(node_filesystem_files{device=~"/dev/.*", device!~"/dev/loop\\d+", job="node-exporter"}) by (device, pod, namespace, cluster)) by (pod, namespace, cluster) * on (namespace, pod, cluster) group_left(node, host_ip, role) node_namespace_pod:kube_pod_info:)
      record: 'node:node_inodes_total:'
      # 计算每个节点可用的inode数
    - expr: |
        sum by(node, host_ip, role, cluster) (sum(max(node_filesystem_files_free{device=~"/dev/.*", device!~"/dev/loop\\d+", job="node-exporter"}) by (device, pod, namespace, cluster)) by (pod, namespace, cluster) * on (namespace, pod, cluster) group_left(node, host_ip, role) node_namespace_pod:kube_pod_info:)
      record: 'node:node_inodes_free:'
      # 计算1分钟平均负载与CPU核数的比例
    - expr: |
        sum by (node, host_ip, role, cluster) (node_load1{job="node-exporter"} * on (namespace, pod, cluster) group_left(node, host_ip, role) node_namespace_pod:kube_pod_info:) / node:node_num_cpu:sum
      record: node:load1:ratio
      # 计算5分钟平均负载与CPU核数的比例
    - expr: |
        sum by (node, host_ip, role, cluster) (node_load5{job="node-exporter"} * on (namespace, pod, cluster) group_left(node, host_ip, role) node_namespace_pod:kube_pod_info:) / node:node_num_cpu:sum
      record: node:load5:ratio
      # 计算15分钟平均负载与CPU核数的比例
    - expr: |
        sum by (node, host_ip, role, cluster) (node_load15{job="node-exporter"} * on (namespace, pod, cluster) group_left(node, host_ip, role) node_namespace_pod:kube_pod_info:) / node:node_num_cpu:sum
      record: node:load15:ratio
      # 计算每个节点上调度的Pod数量
    - expr: |
        sum by (node, host_ip, role, cluster) ((kube_pod_status_scheduled{job="kube-state-metrics", condition="true"} > 0)  * on (namespace, pod, cluster) group_left(node, host_ip, role) node_namespace_pod:kube_pod_info:)
      record: node:pod_count:sum
      # 计算每个节点的Pod调度容量
    - expr: |
        (sum(kube_node_status_capacity{resource="pods", job="kube-state-metrics"}) by (node, cluster) * on(node, cluster) group_left(host_ip, role) max by(node, host_ip, role, cluster) (node_namespace_pod:kube_pod_info:{node!="",host_ip!=""}))
      record: node:pod_capacity:sum
      # 计算每个节点Pod的使用率
    - expr: |
        node:pod_running:count / node:pod_capacity:sum
      record: node:pod_utilization:ratio
      # 计算每个节点正在运行的Pod数量
    - expr: |
        count(node_namespace_pod:kube_pod_info: unless on (pod, namespace, cluster) (kube_pod_status_phase{job="kube-state-metrics", phase=~"Failed|Pending|Unknown|Succeeded"} > 0)) by (node, host_ip, role, cluster)
      record: node:pod_running:count
      # 计算每个节点上成功运行的Pod数量
    - expr: |
        count(node_namespace_pod:kube_pod_info: unless on (pod, namespace, cluster) (kube_pod_status_phase{job="kube-state-metrics", phase=~"Failed|Pending|Unknown|Running"} > 0)) by (node, host_ip, role, cluster)
      record: node:pod_succeeded:count
      # 计算每个节点上异常的Pod数量
    - expr: |
        count(node_namespace_pod:kube_pod_info:{node!="",host_ip!=""} unless on (pod, namespace, cluster) (kube_pod_status_phase{job="kube-state-metrics", phase="Succeeded"}>0) unless on (pod, namespace, cluster) ((kube_pod_status_ready{job="kube-state-metrics", condition="true"}>0) and on (pod, namespace, cluster) (kube_pod_status_phase{job="kube-state-metrics", phase="Running"}>0)) unless on (pod, namespace, cluster) kube_pod_container_status_waiting_reason{job="kube-state-metrics", reason="ContainerCreating"}>0) by (node, host_ip, role, cluster)
      record: node:pod_abnormal:count
      # 计算每个节点上异常Pod的比例
    - expr: |
        node:pod_abnormal:count / count(node_namespace_pod:kube_pod_info:{node!="",host_ip!=""} unless on (pod, namespace, cluster) kube_pod_status_phase{job="kube-state-metrics", phase="Succeeded"}>0) by (node, host_ip, role, cluster)
      record: node:pod_abnormal:ratio
      # 计算每个节点可用的磁盘空间
    - expr: |
        sum(max(node_filesystem_avail_bytes{device=~"/dev/.*", device!~"/dev/loop\\d+", job="node-exporter"} * on (namespace, pod, cluster) group_left(node, host_ip, role) node_namespace_pod:kube_pod_info:) by (device, node, host_ip, role, cluster)) by (node, host_ip, role, cluster)
      record: 'node:disk_space_available:'
      # 计算每个节点的磁盘空间使用率
    - expr: |
        1- sum(max(node_filesystem_avail_bytes{device=~"/dev/.*", device!~"/dev/loop\\d+", job="node-exporter"} * on (namespace, pod, cluster) group_left(node, host_ip, role) node_namespace_pod:kube_pod_info:) by (device, node, host_ip, role, cluster)) by (node, host_ip, role, cluster) / sum(max(node_filesystem_size_bytes{device=~"/dev/.*", device!~"/dev/loop\\d+", job="node-exporter"} * on (namespace, pod, cluster) group_left(node, host_ip, role) node_namespace_pod:kube_pod_info:) by (device, node, host_ip, role, cluster)) by (node, host_ip, role, cluster)
      record: node:disk_space_utilization:ratio
      # 计算每个节点的inode使用率
    - expr: |
        (1 - (node:node_inodes_free: / node:node_inodes_total:))
      record: node:disk_inode_utilization:ratio
  - name: cluster.rules
    rules:
      # 计算每个集群中处于非正常状态的 Pod 数量
    - expr: |
        count by(cluster) (kube_pod_info{job="kube-state-metrics"} unless on (pod, namespace, cluster) (kube_pod_status_phase{job="kube-state-metrics", phase="Succeeded"}>0) unless on (pod, namespace, cluster) ((kube_pod_status_ready{job="kube-state-metrics", condition="true"}>0) and on (pod, namespace, cluster) (kube_pod_status_phase{job="kube-state-metrics", phase="Running"}>0)) unless on (pod, namespace, cluster) kube_pod_container_status_waiting_reason{job="kube-state-metrics", reason="ContainerCreating"}>0)
      record: cluster:pod_abnormal:sum
      # 计算每个集群中总的 Pod 数量
    - expr: |
        sum by(cluster) ((kube_pod_status_scheduled{job="kube-state-metrics", condition="true"} > 0)  * on (namespace, pod, cluster) group_left(node) (sum by (node, namespace, pod, cluster) (kube_pod_info)))
      record: cluster:pod:sum
      # 计算每个集群中非正常 Pod 占总 Pod 的比例
    - expr: |
        cluster:pod_abnormal:sum / sum by(cluster) (kube_pod_status_phase{job="kube-state-metrics", phase!="Succeeded"})
      record: cluster:pod_abnormal:ratio
      # 计算每个集群中处于运行状态的 Pod 数量
    - expr: |
        count by(cluster) (kube_pod_info{job="kube-state-metrics"} and on (pod, namespace, cluster) (kube_pod_status_phase{job="kube-state-metrics", phase="Running"}>0))
      record: cluster:pod_running:count
      # 计算每个集群中 Pod 的使用比例
    - expr: |
        cluster:pod_running:count / sum by(cluster) (kube_node_status_capacity{resource="pods", job="kube-state-metrics"})
      record: cluster:pod_utilization:ratio
      # 计算每个集群中磁盘的使用比例
    - expr: |
        1 - sum by(cluster) (max(node_filesystem_avail_bytes{device=~"/dev/.*", device!~"/dev/loop\\d+", job="node-exporter"}) by (device, instance, cluster)) / sum by(cluster) (max(node_filesystem_size_bytes{device=~"/dev/.*", device!~"/dev/loop\\d+", job="node-exporter"}) by (device, instance, cluster))
      record: cluster:disk_utilization:ratio
      # 计算每个集群中 inode 的使用比例
    - expr: |
        1 - sum by(cluster) (node:node_inodes_free:) / sum by(cluster) (node:node_inodes_total:)
      record: cluster:disk_inode_utilization:ratio
      # 计算每个集群中离线的节点数量
    - expr: |
        sum by(cluster) (kube_node_status_condition{job="kube-state-metrics", condition="Ready", status=~"unknown|false"})
      record: cluster:node_offline:sum
      # 计算每个集群中离线节点占总节点的比例
    - expr: |
        sum by(cluster) (kube_node_status_condition{job="kube-state-metrics", condition="Ready", status=~"unknown|false"}) / sum by(cluster) (kube_node_status_condition{job="kube-state-metrics", condition="Ready"})
      record: cluster:node_offline:ratio
  - name: namespace.rules
    rules:
      # 计算每个命名空间中处于非正常状态的 Pod 数量，包括状态为 ContainerCreating 的 Pod
    - expr: |
        (count by(namespace, cluster) (kube_pod_info{job="kube-state-metrics"} unless on(pod, namespace, cluster) (kube_pod_status_phase{job="kube-state-metrics",phase="Succeeded"} > 0) unless on(pod, namespace, cluster) ((kube_pod_status_ready{condition="true",job="kube-state-metrics"} > 0) and on(pod, namespace, cluster) (kube_pod_status_phase{job="kube-state-metrics",phase="Running"} > 0)) unless on(pod, namespace, cluster) kube_pod_container_status_waiting_reason{job="kube-state-metrics",reason="ContainerCreating"} > 0) or on(namespace, cluster) (group by(namespace, cluster) (kube_pod_info{job="kube-state-metrics"}) * 0)) * on(namespace, cluster) group_left(workspace) (kube_namespace_labels{job="kube-state-metrics"}) > 0
      record: namespace:pod_abnormal:count
      # 计算每个命名空间中非正常 Pod 占总 Pod 的比例
    - expr: |
        namespace:pod_abnormal:count / (sum(kube_pod_status_phase{job="kube-state-metrics", phase!="Succeeded", namespace!=""}) by (namespace, cluster) * on (namespace, cluster) group_left(workspace)(kube_namespace_labels{job="kube-state-metrics"}))
      record: namespace:pod_abnormal:ratio
      # 计算每个命名空间中资源使用情况的比例
    - expr: |
        max(kube_resourcequota{job="kube-state-metrics", type="used"}) by (resource, namespace, cluster) / min(kube_resourcequota{job="kube-state-metrics", type="hard"}) by (resource, namespace, cluster) *  on (namespace, cluster) group_left(workspace) (kube_namespace_labels{job="kube-state-metrics"})
      record: namespace:resourcequota_used:ratio
      # 计算每个命名空间中各个工作负载的 CPU 使用量
    - expr: |
        sum (label_replace(label_join(sum(irate(container_cpu_usage_seconds_total{job="kubelet", pod!="", image!=""}[5m])) by (namespace, pod, cluster) * on (pod, namespace, cluster) group_left(owner_kind,owner_name) label_replace(label_join(label_replace(label_replace(kube_pod_owner{job="kube-state-metrics"},"owner_kind", "Deployment", "owner_kind", "ReplicaSet"), "owner_kind", "Pod", "owner_kind", "<none>"),"tmp",":","owner_name","pod"),"owner_name","$1","tmp","<none>:(.*)"), "workload",":","owner_kind","owner_name"), "workload","$1","workload","(Deployment:.+)-(.+)")) by (namespace, workload, owner_kind, cluster)
      record: namespace:workload_cpu_usage:sum
      # 计算每个命名空间中各个工作负载的内存使用量
    - expr: |
        sum (label_replace(label_join(sum(container_memory_usage_bytes{job="kubelet", pod!="", image!=""}) by (namespace, pod, cluster) * on (pod, namespace, cluster) group_left(owner_kind,owner_name) label_replace(label_join(label_replace(label_replace(kube_pod_owner{job="kube-state-metrics"},"owner_kind", "Deployment", "owner_kind", "ReplicaSet"), "owner_kind", "Pod", "owner_kind", "<none>"),"tmp",":","owner_name","pod"),"owner_name","$1","tmp","<none>:(.*)"), "workload",":","owner_kind","owner_name"), "workload","$1","workload","(Deployment:.+)-(.+)")) by (namespace, workload, owner_kind, cluster)
      record: namespace:workload_memory_usage:sum
      # 计算每个命名空间中各个工作负载的内存使用量（不包括缓存）
    - expr: |
        sum (label_replace(label_join(sum(container_memory_working_set_bytes{job="kubelet", pod!="", image!=""}) by (namespace, pod, cluster) * on (pod, namespace, cluster) group_left(owner_kind,owner_name) label_replace(label_join(label_replace(label_replace(kube_pod_owner{job="kube-state-metrics"},"owner_kind", "Deployment", "owner_kind", "ReplicaSet"), "owner_kind", "Pod", "owner_kind", "<none>"),"tmp",":","owner_name","pod"),"owner_name","$1","tmp","<none>:(.*)"), "workload",":","owner_kind","owner_name"), "workload","$1","workload","(Deployment:.+)-(.+)")) by (namespace, workload, owner_kind, cluster)
      record: namespace:workload_memory_usage_wo_cache:sum
      # 计算每个命名空间中各个工作负载的网络发送字节数（使用 irate 函数）
    - expr: |
        sum (label_replace(label_join(sum(irate(container_network_transmit_bytes_total{pod!="", interface!~"^(cali.+|tunl.+|dummy.+|kube.+|flannel.+|cni.+|docker.+|veth.+|lo.*)", job="kubelet"}[5m])) by (namespace, pod, cluster) * on (pod, namespace, cluster) group_left(owner_kind,owner_name) label_replace(label_join(label_replace(label_replace(kube_pod_owner{job="kube-state-metrics"},"owner_kind", "Deployment", "owner_kind", "ReplicaSet"), "owner_kind", "Pod", "owner_kind", "<none>"),"tmp",":","owner_name","pod"),"owner_name","$1","tmp","<none>:(.*)"), "workload",":","owner_kind","owner_name"), "workload","$1","workload","(Deployment:.+)-(.+)")) by (namespace, workload, owner_kind, cluster)
      record: namespace:workload_net_bytes_transmitted:sum_irate
      # 计算每个命名空间中各个工作负载的网络发送字节数（不使用 irate 函数）
    - expr: |
        sum (label_replace(label_join(sum(container_network_transmit_bytes_total{pod!="", interface!~"^(cali.+|tunl.+|dummy.+|kube.+|flannel.+|cni.+|docker.+|veth.+|lo.*)", job="kubelet"}) by (namespace, pod, cluster) * on (pod, namespace, cluster) group_left(owner_kind,owner_name) label_replace(label_join(label_replace(label_replace(kube_pod_owner{job="kube-state-metrics"},"owner_kind", "Deployment", "owner_kind", "ReplicaSet"), "owner_kind", "Pod", "owner_kind", "<none>"),"tmp",":","owner_name","pod"),"owner_name","$1","tmp","<none>:(.*)"), "workload",":","owner_kind","owner_name"), "workload","$1","workload","(Deployment:.+)-(.+)")) by (namespace, workload, owner_kind, cluster)
      record: namespace:workload_net_bytes_transmitted:sum
      # 计算每个命名空间中各个工作负载的网络接收字节数（使用 irate 函数）
    - expr: |
        sum (label_replace(label_join(sum(irate(container_network_receive_bytes_total{pod!="", interface!~"^(cali.+|tunl.+|dummy.+|kube.+|flannel.+|cni.+|docker.+|veth.+|lo.*)", job="kubelet"}[5m])) by (namespace, pod, cluster) * on (pod, namespace, cluster) group_left(owner_kind,owner_name) label_replace(label_join(label_replace(label_replace(kube_pod_owner{job="kube-state-metrics"},"owner_kind", "Deployment", "owner_kind", "ReplicaSet"), "owner_kind", "Pod", "owner_kind", "<none>"),"tmp",":","owner_name","pod"),"owner_name","$1","tmp","<none>:(.*)"), "workload",":","owner_kind","owner_name"), "workload","$1","workload","(Deployment:.+)-(.+)")) by (namespace, workload, owner_kind, cluster)
      record: namespace:workload_net_bytes_received:sum_irate
      # 计算每个命名空间中各个工作负载的网络接收字节数（不使用 irate 函数）
    - expr: |
        sum (label_replace(label_join(sum(container_network_receive_bytes_total{pod!="", interface!~"^(cali.+|tunl.+|dummy.+|kube.+|flannel.+|cni.+|docker.+|veth.+|lo.*)", job="kubelet"}) by (namespace, pod, cluster) * on (pod, namespace, cluster) group_left(owner_kind,owner_name) label_replace(label_join(label_replace(label_replace(kube_pod_owner{job="kube-state-metrics"},"owner_kind", "Deployment", "owner_kind", "ReplicaSet"), "owner_kind", "Pod", "owner_kind", "<none>"),"tmp",":","owner_name","pod"),"owner_name","$1","tmp","<none>:(.*)"), "workload",":","owner_kind","owner_name"), "workload","$1","workload","(Deployment:.+)-(.+)")) by (namespace, workload, owner_kind, cluster)
      record: namespace:workload_net_bytes_received:sum
      # 计算每个命名空间中各个工作负载的部署未满足副本比例
    - expr: |
        label_replace(label_replace(sum(kube_deployment_status_replicas_unavailable{job="kube-state-metrics"}) by (deployment, namespace, cluster) / sum(kube_deployment_spec_replicas{job="kube-state-metrics"}) by (deployment, namespace, cluster) * on (namespace, cluster) group_left(workspace)(kube_namespace_labels{job="kube-state-metrics"}), "workload","Deployment:$1", "deployment", "(.*)"), "owner_kind","Deployment", "", "")
      record: namespace:deployment_unavailable_replicas:ratio
      # 计算每个命名空间中各个工作负载的 DaemonSet 未满足副本比例
    - expr: |
        label_replace(label_replace(sum(kube_daemonset_status_number_unavailable{job="kube-state-metrics"}) by (daemonset, namespace, cluster) / sum(kube_daemonset_status_desired_number_scheduled{job="kube-state-metrics"}) by (daemonset, namespace, cluster) * on (namespace, cluster) group_left(workspace)(kube_namespace_labels{job="kube-state-metrics"}) , "workload","DaemonSet:$1", "daemonset", "(.*)"), "owner_kind","DaemonSet", "", "")
      record: namespace:daemonset_unavailable_replicas:ratio
      # 计算每个命名空间中各个工作负载的 StatefulSet 未满足副本比例
    - expr: |
        label_replace(label_replace((1 - sum(kube_statefulset_status_replicas_current{job="kube-state-metrics"}) by (statefulset, namespace, cluster) / sum(kube_statefulset_replicas{job="kube-state-metrics"}) by (statefulset, namespace, cluster)) * on (namespace, cluster) group_left(workspace)(kube_namespace_labels{job="kube-state-metrics"}) , "workload","StatefulSet:$1", "statefulset", "(.*)"), "owner_kind","StatefulSet", "", "")
      record: namespace:statefulset_unavailable_replicas:ratio
      # 计算每个命名空间中各个工作负载的资源请求总量
    - expr: |
        sum(kube_pod_container_resource_requests * on (pod, namespace, cluster) group_left(owner_kind,owner_name) label_replace(label_join(label_replace(label_replace(kube_pod_owner{job="kube-state-metrics"},"owner_kind","Deployment","owner_kind","ReplicaSet"),"owner_kind","Pod","owner_kind","<none>"),"tmp",":","owner_name","pod"),"owner_name","$1","tmp","<none>:(.*)")) by (namespace, owner_kind, pod, resource, cluster)* on(namespace, cluster) group_left(workspace)kube_namespace_labels{job="kube-state-metrics"}
      record: namespace:kube_pod_resource_request:sum
      # 计算每个命名空间和工作负载的资源请求总和
    - expr: |
        sum(label_replace(label_join(kube_pod_container_resource_requests * on (pod, namespace, cluster) group_left(owner_kind,owner_name)label_replace(label_join(label_replace(label_replace(kube_pod_owner{job="kube-state-metrics"},"owner_kind","Deployment","owner_kind","ReplicaSet"),"owner_kind","Pod","owner_kind","<none>"),"tmp",":","owner_name","pod"),"owner_name","$1","tmp","<none>:(.*)"),"workload",":","owner_kind","owner_name"),"workload","$1","workload","(Deployment:.+)-(.+)")) by (namespace, workload, resource, cluster)* on(namespace, cluster) group_left(workspace) kube_namespace_labels{job="kube-state-metrics"}
      record: namespace:kube_workload_resource_request:sum
      # 计算每个命名空间、工作负载、Pod 和持久卷声明的总容量
    - expr: |
        sum(label_replace(label_join(kube_pod_spec_volumes_persistentvolumeclaims_info * on (pod, namespace, cluster) group_left(owner_kind,owner_name)label_replace(label_join(label_replace(label_replace(kube_pod_owner{job="kube-state-metrics"},"owner_kind","Deployment","owner_kind","ReplicaSet"),"owner_kind","Pod","owner_kind","<none>"),"tmp",":","owner_name","pod"),"owner_name","$1","tmp","<none>:(.*)"),"workload",":","owner_kind","owner_name"),"workload","$1","workload","(Deployment:.+)-(.+)")) by (namespace, workload, pod, persistentvolumeclaim, cluster)* on(namespace, pod, cluster) group_left(node) kube_pod_info{job="kube-state-metrics"}* on (node, persistentvolumeclaim, namespace, cluster) group_left kubelet_volume_stats_capacity_bytes * on(namespace, cluster) group_left(workspace) kube_namespace_labels{job="kube-state-metrics"}
      record: namespace:pvc_bytes_total:sum
  - name: apiserver.rules
    rules:
      # 记录每个集群的 API 服务器的可用性（up 状态为 1 的数量）
    - expr: |
        sum by(cluster) (up{job="apiserver"} == 1)
      record: apiserver:up:sum
      # 记录每个集群的 API 服务器在最近 5 分钟内请求总数的速率
    - expr: |
        sum by(cluster) (irate(apiserver_request_total{job="apiserver"}[5m]))
      record: apiserver:apiserver_request_total:sum_irate
      # 记录每个集群的 API 服务器在最近 5 分钟内按动词分类的请求总数的速率
    - expr: |
        sum(irate(apiserver_request_total{job="apiserver"}[5m])) by (verb, cluster)
      record: apiserver:apiserver_request_total:sum_verb_irate
      # 计算每个集群的 API 服务器处理非 LIST、WATCH 类型请求的平均耗时
    - expr: |
        sum by(cluster) (irate(apiserver_request_duration_seconds_sum{job="apiserver",subresource!="log", verb!~"LIST|WATCH|WATCHLIST|PROXY|CONNECT"}[5m])) / sum by(cluster) (irate(apiserver_request_duration_seconds_count{job="apiserver", subresource!="log",verb!~"LIST|WATCH|WATCHLIST|PROXY|CONNECT"}[5m]))
      record: apiserver:apiserver_request_duration:avg
      # 计算每个集群的 API 服务器按动词分类处理非 LIST、WATCH 类型请求的平均耗时
    - expr: |
        sum(irate(apiserver_request_duration_seconds_sum{job="apiserver",subresource!="log", verb!~"LIST|WATCH|WATCHLIST|PROXY|CONNECT"}[5m])) by (verb, cluster) / sum(irate(apiserver_request_duration_seconds_count{job="apiserver", subresource!="log",verb!~"LIST|WATCH|WATCHLIST|PROXY|CONNECT"}[5m])) by (verb, cluster)
      record: apiserver:apiserver_request_duration:avg_by_verb
  - name: scheduler.rules
    rules:
      # 记录每个集群的 Kubernetes 调度器的可用性（up 状态为 1 的数量）
    - expr: |
        sum by(cluster) (up{job="kube-scheduler"} == 1)
      record: scheduler:up:sum
      # 记录每个集群的 Kubernetes 调度器的调度尝试次数
    - expr: |
        sum(scheduler_schedule_attempts_total{job="kube-scheduler"}) by (result, cluster)
      record: scheduler:scheduler_schedule_attempts:sum
      # 记录每个集群的 Kubernetes 调度器在最近 5 分钟内的调度尝试次数的速率
    - expr: |
        sum(rate(scheduler_schedule_attempts_total{job="kube-scheduler"}[5m])) by (result, cluster)
      record: scheduler:scheduler_schedule_attempts:sum_rate
      # 计算每个集群的 Kubernetes 调度器端到端调度的平均耗时
    - expr: |
        (sum by(cluster) (rate(scheduler_e2e_scheduling_duration_seconds_sum{job="kube-scheduler"}[1h]))  / sum by(cluster) (rate(scheduler_e2e_scheduling_duration_seconds_count{job="kube-scheduler"}[1h])))
      record: scheduler:scheduler_e2e_scheduling_duration:avg
  - name: scheduler_histogram.rules
    rules:
      # 计算每个集群的 Kubernetes 调度器端到端调度的 99% 耗时分位数
    - expr: |
        histogram_quantile(0.99, sum(rate(scheduler_e2e_scheduling_duration_seconds_bucket{job="kube-scheduler"}[1h])) by (le, cluster) )
      labels:
        quantile: "0.99"
      record: scheduler:scheduler_e2e_scheduling_duration:histogram_quantile
      # 计算每个集群的 Kubernetes 调度器端到端调度的 90% 耗时分位数
    - expr: |
        histogram_quantile(0.9, sum(rate(scheduler_e2e_scheduling_duration_seconds_bucket{job="kube-scheduler"}[1h])) by (le, cluster) )
      labels:
        quantile: "0.9"
      record: scheduler:scheduler_e2e_scheduling_duration:histogram_quantile
      # 计算每个集群的 Kubernetes 调度器端到端调度的 50% 耗时分位数
    - expr: |
        histogram_quantile(0.5, sum(rate(scheduler_e2e_scheduling_duration_seconds_bucket{job="kube-scheduler"}[1h])) by (le, cluster) )
      labels:
        quantile: "0.5"
      record: scheduler:scheduler_e2e_scheduling_duration:histogram_quantile
  - name: controller_manager.rules
    rules:
      # 记录每个集群的 Kubernetes 控制器管理器的可用性（up 状态为 1 的数量）
    - expr: |
        sum by(cluster) (up{job="kube-controller-manager"} == 1)
      record: controller_manager:up:sum
  - name: coredns.rules
    rules:
      # 记录每个集群的 CoreDNS 的可用性（up 状态为 1 的数量）
    - expr: |
        sum by(cluster) (up{job="coredns"} == 1)
      record: coredns:up:sum
  - name: kube-apiserver-burnrate.rules
    rules:
      # 计算每个集群的 API 服务器在 1 天内处理 LIST 或 GET 请求的“燃烧率”（burn rate），即处理慢的请求和错误请求的比例
    - expr: |
        (
          (
            # too slow
            sum by (cluster) (rate(apiserver_request_duration_seconds_count{job="apiserver",verb=~"LIST|GET"}[1d]))
            -
            (
              (
                sum by (cluster) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope=~"resource|",le="1"}[1d]))
                or
                vector(0)
              )
              +
              sum by (cluster) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope="namespace",le="5"}[1d]))
              +
              sum by (cluster) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope="cluster",le="30"}[1d]))
            )
          )
          +
          # errors
          sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET",code=~"5.."}[1d]))
        )
        /
        sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET"}[1d]))
      labels:
        verb: read
      record: apiserver_request:burnrate1d
      # 计算每个集群的 API 服务器在 1 小时内处理 LIST 或 GET 请求的“燃烧率”，即处理慢的请求和错误请求的比例
    - expr: |
        (
          (
            # too slow
            sum by (cluster) (rate(apiserver_request_duration_seconds_count{job="apiserver",verb=~"LIST|GET"}[1h]))
            -
            (
              (
                sum by (cluster) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope=~"resource|",le="1"}[1h]))
                or
                vector(0)
              )
              +
              sum by (cluster) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope="namespace",le="5"}[1h]))
              +
              sum by (cluster) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope="cluster",le="30"}[1h]))
            )
          )
          +
          # errors
          sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET",code=~"5.."}[1h]))
        )
        /
        sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET"}[1h]))
      labels:
        verb: read
      record: apiserver_request:burnrate1h
      # 计算每个集群的 API 服务器在 2 小时内处理 LIST 或 GET 请求的“燃烧率”，即处理慢的请求和错误请求的比例
    - expr: |
        (
          (
            # too slow
            sum by (cluster) (rate(apiserver_request_duration_seconds_count{job="apiserver",verb=~"LIST|GET"}[2h]))
            -
            (
              (
                sum by (cluster) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope=~"resource|",le="1"}[2h]))
                or
                vector(0)
              )
              +
              sum by (cluster) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope="namespace",le="5"}[2h]))
              +
              sum by (cluster) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope="cluster",le="30"}[2h]))
            )
          )
          +
          # errors
          sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET",code=~"5.."}[2h]))
        )
        /
        sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET"}[2h]))
      labels:
        verb: read
      record: apiserver_request:burnrate2h
      # 计算每个集群的 API 服务器在 30 分钟内处理 LIST 或 GET 请求的“燃烧率”，即处理慢的请求和错误请求的比例
    - expr: |
        (
          (
            # too slow
            sum by (cluster) (rate(apiserver_request_duration_seconds_count{job="apiserver",verb=~"LIST|GET"}[30m]))
            -
            (
              (
                sum by (cluster) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope=~"resource|",le="1"}[30m]))
                or
                vector(0)
              )
              +
              sum by (cluster) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope="namespace",le="5"}[30m]))
              +
              sum by (cluster) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope="cluster",le="30"}[30m]))
            )
          )
          +
          # errors
          sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET",code=~"5.."}[30m]))
        )
        /
        sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET"}[30m]))
      labels:
        verb: read
        # 计算每个集群的 API 服务器在 3 天内处理 LIST 或 GET 请求的“燃烧率”，即处理慢的请求和错误请求的比例
      record: apiserver_request:burnrate30m
    - expr: |
        (
          (
            # too slow
            sum by (cluster) (rate(apiserver_request_duration_seconds_count{job="apiserver",verb=~"LIST|GET"}[3d]))
            -
            (
              (
                sum by (cluster) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope=~"resource|",le="1"}[3d]))
                or
                vector(0)
              )
              +
              sum by (cluster) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope="namespace",le="5"}[3d]))
              +
              sum by (cluster) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope="cluster",le="30"}[3d]))
            )
          )
          +
          # errors
          sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET",code=~"5.."}[3d]))
        )
        /
        sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET"}[3d]))
      labels:
        verb: read
      record: apiserver_request:burnrate3d
      # 计算每个集群的 API 服务器在 5 分钟内处理 LIST 或 GET 请求的“燃烧率”，即处理慢的请求和错误请求的比例
    - expr: |
        (
          (
            # too slow
            sum by (cluster) (rate(apiserver_request_duration_seconds_count{job="apiserver",verb=~"LIST|GET"}[5m]))
            -
            (
              (
                sum by (cluster) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope=~"resource|",le="1"}[5m]))
                or
                vector(0)
              )
              +
              sum by (cluster) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope="namespace",le="5"}[5m]))
              +
              sum by (cluster) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope="cluster",le="30"}[5m]))
            )
          )
          +
          # errors
          sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET",code=~"5.."}[5m]))
        )
        /
        sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET"}[5m]))
      labels:
        verb: read
      record: apiserver_request:burnrate5m
      # 计算每个集群的 API 服务器在 6 小时内处理 LIST 或 GET 请求的“燃烧率”，即处理慢的请求和错误请求的比例
    - expr: |
        (
          (
            # too slow
            sum by (cluster) (rate(apiserver_request_duration_seconds_count{job="apiserver",verb=~"LIST|GET"}[6h]))
            -
            (
              (
                sum by (cluster) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope=~"resource|",le="1"}[6h]))
                or
                vector(0)
              )
              +
              sum by (cluster) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope="namespace",le="5"}[6h]))
              +
              sum by (cluster) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",scope="cluster",le="30"}[6h]))
            )
          )
          +
          # errors
          sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET",code=~"5.."}[6h]))
        )
        /
        sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET"}[6h]))
      labels:
        verb: read
      record: apiserver_request:burnrate6h
      # 计算每个集群的 API 服务器在 1 天内处理 POST、PUT、PATCH 或 DELETE 请求的“燃烧率”，即处理慢的请求和错误请求的比例
    - expr: |
        (
          (
            # too slow
            sum by (cluster) (rate(apiserver_request_duration_seconds_count{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[1d]))
            -
            sum by (cluster) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",le="1"}[1d]))
          )
          +
          sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",code=~"5.."}[1d]))
        )
        /
        sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[1d]))
      labels:
        verb: write
      record: apiserver_request:burnrate1d
      # 计算每个集群的 API 服务器在 1 小时内处理 POST、PUT、PATCH 或 DELETE 请求的“燃烧率”，即处理慢的请求和错误请求的比例
    - expr: |
        (
          (
            # too slow
            sum by (cluster) (rate(apiserver_request_duration_seconds_count{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[1h]))
            -
            sum by (cluster) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",le="1"}[1h]))
          )
          +
          sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",code=~"5.."}[1h]))
        )
        /
        sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[1h]))
      labels:
        verb: write
      record: apiserver_request:burnrate1h
      # 计算每个集群的 API 服务器在 2 小时内处理 POST、PUT、PATCH 或 DELETE 请求的“燃烧率”，即处理慢的请求和错误请求的比例
    - expr: |
        (
          (
            # too slow
            sum by (cluster) (rate(apiserver_request_duration_seconds_count{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[2h]))
            -
            sum by (cluster) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",le="1"}[2h]))
          )
          +
          sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",code=~"5.."}[2h]))
        )
        /
        sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[2h]))
      labels:
        verb: write
      record: apiserver_request:burnrate2h
      # 计算每个集群的 API 服务器在 30 分钟内处理 POST、PUT、PATCH 或 DELETE 请求的“燃烧率”，即处理慢的请求和错误请求的比例
    - expr: |
        (
          (
            # too slow
            sum by (cluster) (rate(apiserver_request_duration_seconds_count{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[30m]))
            -
            sum by (cluster) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",le="1"}[30m]))
          )
          +
          sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",code=~"5.."}[30m]))
        )
        /
        sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[30m]))
      labels:
        verb: write
      record: apiserver_request:burnrate30m
      # 计算每个集群的 API 服务器在 3 天内处理 POST、PUT、PATCH 或 DELETE 请求的“燃烧率”，即处理慢的请求和错误请求的比例
    - expr: |
        (
          (
            # too slow
            sum by (cluster) (rate(apiserver_request_duration_seconds_count{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[3d]))
            -
            sum by (cluster) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",le="1"}[3d]))
          )
          +
          sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",code=~"5.."}[3d]))
        )
        /
        sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[3d]))
      labels:
        verb: write
      record: apiserver_request:burnrate3d
      # 计算每个集群的 API 服务器在 5 分钟内处理 POST、PUT、PATCH 或 DELETE 请求的“燃烧率”，即处理慢的请求和错误请求的比例
    - expr: |
        (
          (
            # too slow
            sum by (cluster) (rate(apiserver_request_duration_seconds_count{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[5m]))
            -
            sum by (cluster) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",le="1"}[5m]))
          )
          +
          sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",code=~"5.."}[5m]))
        )
        /
        sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[5m]))
      labels:
        verb: write
      record: apiserver_request:burnrate5m
      # 计算每个集群的 API 服务器在 6 小时内处理 POST、PUT、PATCH 或 DELETE 请求的“燃烧率”，即处理慢的请求和错误请求的比例
    - expr: |
        (
          (
            # too slow
            sum by (cluster) (rate(apiserver_request_duration_seconds_count{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[6h]))
            -
            sum by (cluster) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",le="1"}[6h]))
          )
          +
          sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",code=~"5.."}[6h]))
        )
        /
        sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[6h]))
      labels:
        verb: write
      record: apiserver_request:burnrate6h
  - name: kube-apiserver-histogram.rules
    rules:
      # 计算每个集群的 API 服务器在 5 分钟内处理 LIST 或 GET 请求的 99% 耗时分位数，仅记录大于 0 的值
    - expr: |
        histogram_quantile(0.99, sum by (cluster, le, resource) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET"}[5m]))) > 0
      labels:
        quantile: "0.99"
        verb: read
      record: cluster_quantile:apiserver_request_duration_seconds:histogram_quantile
      # 计算每个集群的 API 服务器在 5 分钟内处理 POST、PUT、PATCH 或 DELETE 请求的 99% 耗时分位数，仅记录大于 0 的值
    - expr: |
        histogram_quantile(0.99, sum by (cluster, le, resource) (rate(apiserver_request_duration_seconds_bucket{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[5m]))) > 0
      labels:
        quantile: "0.99"
        verb: write
      record: cluster_quantile:apiserver_request_duration_seconds:histogram_quantile
      # 计算每个集群的 API 服务器在 5 分钟内处理非 LIST、WATCH 等特定子资源和动词的请求的 99% 耗时分位数，排除了实例和 Pod 的影响，仅记录大于 0 的值
    - expr: |
        histogram_quantile(0.99, sum(rate(apiserver_request_duration_seconds_bucket{job="apiserver",subresource!="log",verb!~"LIST|WATCH|WATCHLIST|DELETECOLLECTION|PROXY|CONNECT"}[5m])) without(instance, pod))
      labels:
        quantile: "0.99"
      record: cluster_quantile:apiserver_request_duration_seconds:histogram_quantile
      # 计算每个集群的 API 服务器在 5 分钟内处理非 LIST、WATCH 等特定子资源和动词的请求的 90% 耗时分位数，排除了实例和 Pod 的影响
    - expr: |
        histogram_quantile(0.9, sum(rate(apiserver_request_duration_seconds_bucket{job="apiserver",subresource!="log",verb!~"LIST|WATCH|WATCHLIST|DELETECOLLECTION|PROXY|CONNECT"}[5m])) without(instance, pod))
      labels:
        quantile: "0.9"
      record: cluster_quantile:apiserver_request_duration_seconds:histogram_quantile
      # 计算每个集群的 API 服务器在 5 分钟内处理非 LIST、WATCH 等特定子资源和动词的请求的 50% 耗时分位数，排除了实例和 Pod 的影响
    - expr: |
        histogram_quantile(0.5, sum(rate(apiserver_request_duration_seconds_bucket{job="apiserver",subresource!="log",verb!~"LIST|WATCH|WATCHLIST|DELETECOLLECTION|PROXY|CONNECT"}[5m])) without(instance, pod))
      labels:
        quantile: "0.5"
      record: cluster_quantile:apiserver_request_duration_seconds:histogram_quantile
  - interval: 3m
    name: kube-apiserver-availability.rules
    rules:
      # 计算过去 30 天每小时的 API 服务器请求总数的平均值，并将结果乘以每天的小时数和天数
    - expr: |
        avg_over_time(code_verb:apiserver_request_total:increase1h[30d]) * 24 * 30
      record: code_verb:apiserver_request_total:increase30d
      # 计算每个集群在 30 天内处理 LIST 或 GET 请求的请求总数，标记为读操作
    - expr: |
        sum by (cluster, code) (code_verb:apiserver_request_total:increase30d{verb=~"LIST|GET"})
      labels:
        verb: read
      record: code:apiserver_request_total:increase30d
      # 计算每个集群在 30 天内处理 POST、PUT、PATCH 或 DELETE 请求的请求总数，标记为写操作
    - expr: |
        sum by (cluster, code) (code_verb:apiserver_request_total:increase30d{verb=~"POST|PUT|PATCH|DELETE"})
      labels:
        verb: write
      record: code:apiserver_request_total:increase30d
      # 计算每个集群、动词和作用域在 1 小时内的 API 服务器请求持续时间计数的总和
    - expr: |
        sum by (cluster, verb, scope) (increase(apiserver_request_duration_seconds_count[1h]))
      record: cluster_verb_scope:apiserver_request_duration_seconds_count:increase1h
      # 计算每个集群、动词和作用域在 30 天内的 API 服务器请求持续时间计数的平均值，并将其乘以每天的小时数和天数
    - expr: |
        sum by (cluster, verb, scope) (avg_over_time(cluster_verb_scope:apiserver_request_duration_seconds_count:increase1h[30d]) * 24 * 30)
      record: cluster_verb_scope:apiserver_request_duration_seconds_count:increase30d
      # 计算每个集群、动词、作用域和阈值（le）在 1 小时内的 API 服务器请求持续时间桶计数的总和
    - expr: |
        sum by (cluster, verb, scope, le) (increase(apiserver_request_duration_seconds_bucket[1h]))
      record: cluster_verb_scope_le:apiserver_request_duration_seconds_bucket:increase1h
      # 计算每个集群、动词、作用域和阈值（le）在 30 天内的 API 服务器请求持续时间桶计数的平均值，并将其乘以每天的小时数和天数
    - expr: |
        sum by (cluster, verb, scope, le) (avg_over_time(cluster_verb_scope_le:apiserver_request_duration_seconds_bucket:increase1h[30d]) * 24 * 30)
      record: cluster_verb_scope_le:apiserver_request_duration_seconds_bucket:increase30d
      # 计算每个集群的 API 服务器在 30 天内所有请求的可用性，包括写操作（POST、PUT、PATCH、DELETE）慢请求、读操作（LIST、GET）慢请求和错误请求（5xx）的比例
    - expr: |
        1 - (
          (
            # write too slow
            sum by (cluster) (cluster_verb_scope:apiserver_request_duration_seconds_count:increase30d{verb=~"POST|PUT|PATCH|DELETE"})
            -
            sum by (cluster) (cluster_verb_scope_le:apiserver_request_duration_seconds_bucket:increase30d{verb=~"POST|PUT|PATCH|DELETE",le="1"})
          ) +
          (
            # read too slow
            sum by (cluster) (cluster_verb_scope:apiserver_request_duration_seconds_count:increase30d{verb=~"LIST|GET"})
            -
            (
              (
                sum by (cluster) (cluster_verb_scope_le:apiserver_request_duration_seconds_bucket:increase30d{verb=~"LIST|GET",scope=~"resource|",le="1"})
                or
                vector(0)
              )
              +
              sum by (cluster) (cluster_verb_scope_le:apiserver_request_duration_seconds_bucket:increase30d{verb=~"LIST|GET",scope="namespace",le="5"})
              +
              sum by (cluster) (cluster_verb_scope_le:apiserver_request_duration_seconds_bucket:increase30d{verb=~"LIST|GET",scope="cluster",le="30"})
            )
          ) +
          # errors
          sum by (cluster) (code:apiserver_request_total:increase30d{code=~"5.."} or vector(0))
        )
        /
        sum by (cluster) (code:apiserver_request_total:increase30d)
      labels:
        verb: all
      record: apiserver_request:availability30d
      # 计算每个集群的 API 服务器在 30 天内读操作（LIST、GET）请求的可用性，包括慢请求和错误请求（5xx）的比例
    - expr: |
        1 - (
          sum by (cluster) (cluster_verb_scope:apiserver_request_duration_seconds_count:increase30d{verb=~"LIST|GET"})
          -
          (
            # too slow
            (
              sum by (cluster) (cluster_verb_scope_le:apiserver_request_duration_seconds_bucket:increase30d{verb=~"LIST|GET",scope=~"resource|",le="1"})
              or
              vector(0)
            )
            +
            sum by (cluster) (cluster_verb_scope_le:apiserver_request_duration_seconds_bucket:increase30d{verb=~"LIST|GET",scope="namespace",le="5"})
            +
            sum by (cluster) (cluster_verb_scope_le:apiserver_request_duration_seconds_bucket:increase30d{verb=~"LIST|GET",scope="cluster",le="30"})
          )
          +
          # errors
          sum by (cluster) (code:apiserver_request_total:increase30d{verb="read",code=~"5.."} or vector(0))
        )
        /
        sum by (cluster) (code:apiserver_request_total:increase30d{verb="read"})
      labels:
        verb: read
      record: apiserver_request:availability30d
      # 计算每个集群的 API 服务器在 30 天内写操作（POST、PUT、PATCH、DELETE）请求的可用性，包括慢请求和错误请求（5xx）的比例
    - expr: |
        1 - (
          (
            # too slow
            sum by (cluster) (cluster_verb_scope:apiserver_request_duration_seconds_count:increase30d{verb=~"POST|PUT|PATCH|DELETE"})
            -
            sum by (cluster) (cluster_verb_scope_le:apiserver_request_duration_seconds_bucket:increase30d{verb=~"POST|PUT|PATCH|DELETE",le="1"})
          )
          +
          # errors
          sum by (cluster) (code:apiserver_request_total:increase30d{verb="write",code=~"5.."} or vector(0))
        )
        /
        sum by (cluster) (code:apiserver_request_total:increase30d{verb="write"})
      labels:
        verb: write
      record: apiserver_request:availability30d
      # 计算每个集群在最近 5 分钟内处理 LIST 或 GET 请求的请求总数，按集群、HTTP 状态码和资源类型聚合
    - expr: |
        sum by (cluster,code,resource) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET"}[5m]))
      labels:
        verb: read
      record: code_resource:apiserver_request_total:rate5m
      # 计算每个集群在最近 5 分钟内处理 POST、PUT、PATCH 或 DELETE 请求的请求总数，按集群、HTTP 状态码和资源类型聚合
    - expr: |
        sum by (cluster,code,resource) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[5m]))
      labels:
        verb: write
      record: code_resource:apiserver_request_total:rate5m
      # 计算每个集群在最近 1 小时内处理所有请求（LIST、GET、POST、PUT、PATCH、DELETE）且状态码为 2xx 的请求总数，按集群、HTTP 状态码和动词聚合
    - expr: |
        sum by (cluster, code, verb) (increase(apiserver_request_total{job="apiserver",verb=~"LIST|GET|POST|PUT|PATCH|DELETE",code=~"2.."}[1h]))
      record: code_verb:apiserver_request_total:increase1h
      # 计算每个集群在最近 1 小时内处理所有请求（LIST、GET、POST、PUT、PATCH、DELETE）且状态码为 3xx 的请求总数，按集群、HTTP 状态码和动词聚合
    - expr: |
        sum by (cluster, code, verb) (increase(apiserver_request_total{job="apiserver",verb=~"LIST|GET|POST|PUT|PATCH|DELETE",code=~"3.."}[1h]))
      record: code_verb:apiserver_request_total:increase1h
      # 计算每个集群在最近 1 小时内处理所有请求（LIST、GET、POST、PUT、PATCH、DELETE）且状态码为 4xx 的请求总数，按集群、HTTP 状态码和动词聚合
    - expr: |
        sum by (cluster, code, verb) (increase(apiserver_request_total{job="apiserver",verb=~"LIST|GET|POST|PUT|PATCH|DELETE",code=~"4.."}[1h]))
      record: code_verb:apiserver_request_total:increase1h
      # 计算每个集群在最近 1 小时内处理所有请求（LIST、GET、POST、PUT、PATCH、DELETE）且状态码为 5xx 的请求总数，按集群、HTTP 状态码和动词聚合
    - expr: |
        sum by (cluster, code, verb) (increase(apiserver_request_total{job="apiserver",verb=~"LIST|GET|POST|PUT|PATCH|DELETE",code=~"5.."}[1h]))
      record: code_verb:apiserver_request_total:increase1h
  - name: kubelet.rules
    rules:
      # 计算每个节点的 Kubelet Pod 生命周期事件生成器（PLEG）重新列表操作的 99% 耗时分位数
    - expr: |
        histogram_quantile(0.99, sum(rate(kubelet_pleg_relist_duration_seconds_bucket[5m])) by (instance, le, cluster) * on(instance, cluster) group_left(node) kubelet_node_name{job="kubelet"})
      labels:
        quantile: "0.99"
      record: node_quantile:kubelet_pleg_relist_duration_seconds:histogram_quantile
      # 计算每个节点的 Kubelet PLEG 重新列表操作的 90% 耗时分位数
    - expr: |
        histogram_quantile(0.9, sum(rate(kubelet_pleg_relist_duration_seconds_bucket[5m])) by (instance, le, cluster) * on(instance, cluster) group_left(node) kubelet_node_name{job="kubelet"})
      labels:
        quantile: "0.9"
      record: node_quantile:kubelet_pleg_relist_duration_seconds:histogram_quantile
      # 计算每个节点的 Kubelet PLEG 重新列表操作的 50% 耗时分位数
    - expr: |
        histogram_quantile(0.5, sum(rate(kubelet_pleg_relist_duration_seconds_bucket[5m])) by (instance, le, cluster) * on(instance, cluster) group_left(node) kubelet_node_name{job="kubelet"})
      labels:
        quantile: "0.5"
      record: node_quantile:kubelet_pleg_relist_duration_seconds:histogram_quantile
